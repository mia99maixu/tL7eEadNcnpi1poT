{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2qfAtCQODFa",
        "outputId": "3ae6894c-9189-4e08-aa99-6ccfcc5a249f"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "      id                                          job_title  \\\n",
            "72    73  Aspiring Human Resources Manager, seeking inte...   \n",
            "45    46              Aspiring Human Resources Professional   \n",
            "57    58              Aspiring Human Resources Professional   \n",
            "16    17              Aspiring Human Resources Professional   \n",
            "32    33              Aspiring Human Resources Professional   \n",
            "..   ...                                                ...   \n",
            "22    23    Advisory Board Member at Celal Bayar University   \n",
            "21    22             People Development Coordinator at Ryan   \n",
            "19    20  Native English Teacher at EPIK (English Progra...   \n",
            "17    18             People Development Coordinator at Ryan   \n",
            "103  104   Director Of Administration at Excellence Logging   \n",
            "\n",
            "                                location connection       fit  \n",
            "72                   Houston, Texas Area          7  1.000000  \n",
            "45   Raleigh-Durham, North Carolina Area         44  0.936737  \n",
            "57   Raleigh-Durham, North Carolina Area         44  0.936737  \n",
            "16   Raleigh-Durham, North Carolina Area         44  0.936737  \n",
            "32   Raleigh-Durham, North Carolina Area         44  0.936737  \n",
            "..                                   ...        ...       ...  \n",
            "22                        İzmir, Türkiye      500+   0.000000  \n",
            "21                         Denton, Texas      500+   0.000000  \n",
            "19                                Kanada      500+   0.000000  \n",
            "17                         Denton, Texas      500+   0.000000  \n",
            "103                          Katy, Texas      500+   0.000000  \n",
            "\n",
            "[104 rows x 5 columns]\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "# Load the dataset\n",
        "url = 'https://docs.google.com/spreadsheets/d/117X6i53dKiO7w6kuA1g1TpdTlv1173h_dPlJt5cNNMU/export?format=csv'\n",
        "df = pd.read_csv(url)\n",
        "\n",
        "# Define the keywords related to searching\n",
        "keywords = [\"aspiring human resources\", \"seeking human resources\"]\n",
        "\n",
        "# Combine the keywords into a single string for comparison\n",
        "keyword_str = \" \".join(keywords)\n",
        "\n",
        "# Step 1: Use TF-IDF to vectorize both job titles and keywords\n",
        "tfidf = TfidfVectorizer()\n",
        "job_titles_tfidf = tfidf.fit_transform(df['job_title'].fillna(''))\n",
        "keyword_tfidf = tfidf.transform([keyword_str])\n",
        "\n",
        "# Step 2: Calculate similarity between job titles and the keywords\n",
        "similarity_scores = cosine_similarity(job_titles_tfidf, keyword_tfidf).flatten()\n",
        "\n",
        "# Step 3: Normalize similarity scores\n",
        "scores = (similarity_scores - similarity_scores.min()) / (similarity_scores.max() - similarity_scores.min())\n",
        "\n",
        "# Step 4: Update the 'fit' column with the calculated fitness scores\n",
        "df['fit'] = scores\n",
        "\n",
        "# Step 5: Rank the candidates by fit score\n",
        "df_ranked = df.sort_values(by='fit', ascending=False)\n",
        "\n",
        "# Display the ranked dataset\n",
        "print(df_ranked[['id', 'job_title', 'location', 'connection', 'fit']])"
      ]
    }
  ]
}